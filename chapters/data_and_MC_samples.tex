The discussion of this section is elaborated upon~\cite{CMS-AN-2017-175} and \cite{CMS-AN-2017-159} as these studies use a similar set of data and MC samples.

The data analysed for present study consists of the 2016{B-H} data taking periods for a total certified luminosity of 35.9~\fbinv for all the channels analysed. The luminosity has been computed with the \textsc{brilcalc} tool~\cite{site:brilcalc} using the following command:

\begin{lstlisting}[language=sh, breaklines=true]
brilcalc lumi  -b "STABLE BEAMS" --normtag /afs/cern.ch/user/l/lumipro/public/Normtags/normtag_DATACERT.json -i lumiSummary.json
\end{lstlisting}

All data used for this study are listed in Table~\ref{tab:datasets}. The different denominations of the data sets correspond to a different release of the reconstruction module and trigger menus in CMSSW~\cite{twiki:cmssw} - the collection of software that is used in simulation, calibration, alignment and reconstruction so that it is possible to perform a physics analysis. 

\begin{table}[htb]
\begin{center}
\caption{Primary datasets used in this analysis. PD is an abbreviation for SingleMuon or SingleElectron~\cite{CMS-AN-2017-159}.}
\label{tab:datasets}
\begin{tabular}{ lc }
\hline
Primary dataset                    & Integrated luminosity\\
\hline
/PD/Run2016B-23Sep2016-v3/MINIAOD  & \multirow{8}{*}{35.9 \fbinv}\\
/PD/Run2016C-23Sep2016-v1/MINIAOD  & \\
/PD/Run2016D-23Sep2016-v1/MINIAOD  & \\
/PD/Run2016E-23Sep2016-v1/MINIAOD  & \\
/PD/Run2016F-23Sep2016-v1/MINIAOD  & \\
/PD/Run2016G-23Sep2016-v1/MINIAOD  & \\
/PD/Run2016H-PromptReco-v2/MINIAOD & \\
/PD/Run2016H-PromptReco-v3/MINIAOD & \\\cline{1-2}
\hline
\end{tabular}
\end{center}
\end{table}

Data is compared to samples simulated by Monte Carlo packages~(\cite{Webber:1986mc}, \cite{Sjostrand:2006su}) that use pseudorandom numbers to reproduce quantummechanical probabilities of a process. They rely on the numerical technique developed by Stanisław Ulam~(\cite{Eckart}, \cite{Metropolis}). The use of Monte Carlo samples in a physics analysis allows the separation of signal from background processes and to see how accurately we can model the processes in the real world.

The hardest emission of the nominal \ttbar sample is first generated by the \POWHEG method~\cite{Frixione:2007vw} using full NLO accuracy and taking spin correlations of the decay products of the top quark into account~\cite{Frixione:2007nw}. The showering was implemented in \PYTHIA 8.2~\cite{Sjostrand:2014zea} that is based on dipole-style \pt ordered evolution. \POWHEG and \PYTHIA 8.2 are interfaced via the Les Houches Accord (LHA)~\cite{Boos:2001cv}. Les Houches Event Files (LHEF)~(\cite{Alwall:2006yp}, \cite{Andersen:2014efa}) are used to transfer information about the particles generated by \POWHEG in the hard proccess of interest (\ttbar) to \PYTHIA 8.2. The tune CUETP8M2T4~\cite{Kovalchuk:CR} is used for \PYTHIA 8.2 that specifically aims to specify the parameters of colour reconnection to produce new samples for top mass measurement. The generated events are reconstructed with the CMS detector simulation based on \GEANTfour~\cite{Agostinelli:2002hh}.

Madgraph5\_aMC@NLO~\cite{Alwall:2014hca} is a popular choice to generate hard radiation to the NLO order for background processes. 

The list of simulated samples can be found in Table~\ref{tab:mcdatasets}. They are from the

RunIISummer16MiniAODv2-PUMoriond17\_80X\_mcRun2\_asymptotic\_2016\_TrancheIV\_v6

production.

The cross sections are theoretical predictions. Practically, they are obtained from~\cite{twiki:SingleTopRefXsec} and \cite{twiki:SM13} except for \ttbar for which the generator cross section is quoted according to~\cite{site:MCM}. At NNLO the expected \ttbar cross section is $832^{+20}_{-29}~(\text{scale})~\pm 35~(\text{PDF}+\alpha_S)$~\cite{twiki:TTbarNLO}. We use the NNLO reference to normalise all \ttbar samples.

\begin{longtable}{ p{0.16\textwidth}ll }
\caption{List of simulation samples. We quote the cross section used to normalise the sample in the analysis. Adapted after~\cite{CMS-AN-2017-159}.}\\
\hline
\label{tab:mcdatasets}
Process                      & Dataset                                                                     & $\sigma[pb]$\\
\hline
\multicolumn{3}{l}{\bf Signal} \\
\hline
\ttbar                       & \small  TT\_TuneCUETP8M2T4\_13TeV-powheg-pythia8                            & 832\\
\hline
\multicolumn{3}{l}{\bf Background} \\
\hline
\multirow{2}{*}{\ttbar+\PW\ }  & \small TTWJetsToLNu\_TuneCUETP8M1\_13TeV-amcatnloFXFX-madspin-pythia8       & 0.20 \\
                             & \small TTWJetsToQQ\_TuneCUETP8M1\_13TeV-amcatnloFXFX-madspin-pythia8        & 0.41 \\\hline
\multirow{2}{*}{\ttbar+\cPZ} & \small TTZToQQ\_TuneCUETP8M1\_13TeV-amcatnlo-pythia                        & 0.53 \\
                             & \small TTZToLLNuNu\_M-10\_TuneCUETP8M1\_13TeV-amcatnlo-pythia8              & 0.25 \\\hline
\PW\ \cPZ                      & \small WZTo3LNu\_TuneCUETP8M1\_13TeV-amcatnloFXFX-pythia8                   & 5.26 \\\hline
\multirow{2}{*}{\PW\ \PW\ }      & \small WWToLNuQQ\_13TeV-powheg                                              & 50.0 \\
                             & \small WWTo2L2Nu\_13TeV-powheg                                              & 12.2 \\\hline
\multirow{2}{*}{\cPZ\cPZ}    & \small ZZTo2L2Nu\_13TeV\_powheg\_pythia8                                    & 0.564 \\
                             & \small ZZTo2L2Q\_13TeV\_amcatnloFXFX\_madspin\_pythia8                      & 3.22 \\\hline
\multirow{3}{*}{\PW\ +jets}    & \small WToLNu\_0J\_13TeV-amcatnloFXFX-pythia8                               & 49540 \\
                             & \small WToLNu\_1J\_13TeV-amcatnloFXFX-pythia8                               & 8041 \\
                             & \small WToLNu\_2J\_13TeV-amcatnloFXFX-pythia8                               & 3052 \\\hline
\multirow{2}{*}{Drell-Yan}   & \small DYJetsToLL\_M-10to50\_TuneCUETP8M1\_13TeV-madgraphMLM-pythia8        & 18610 \\
                             & \small DYJetsToLL\_M-50\_TuneCUETP8M1\_13TeV-madgraphMLM-pythia8            & 6025 \\\hline
\multirow{10}{=}{QCD $\mu$ enriched}
                             & \small QCD\_Pt-30to50\_MuEnrichedPt5\_TuneCUETP8M1\_13TeV\_pythia8          & 1652471.46\\ 
                             & \small QCD\_Pt-50to80\_MuEnrichedPt5\_TuneCUETP8M1\_13TeV\_pythia8          & 437504.1\\
                             & \small QCD\_Pt-80to120\_MuEnrichedPt5\_TuneCUETP8M1\_13TeV\_pythia8         & 106033.66\\
                             & \small QCD\_Pt-120to170\_MuEnrichedPt5\_TuneCUETP8M1\_13TeV\_pythia8        & 25190.52\\
                             & \small QCD\_Pt-170to300\_MuEnrichedPt5\_TuneCUETP8M1\_13TeV\_pythia8        & 8654.49\\
                             & \small QCD\_Pt-300to470\_MuEnrichedPt5\_TuneCUETP8M1\_13TeV\_pythia8        & 797.35\\
                             & \small QCD\_Pt-470to600\_MuEnrichedPt5\_TuneCUETP8M1\_13TeV\_pythia8        & 45.83\\
                             & \small QCD\_Pt-600to800\_MuEnrichedPt5\_TuneCUETP8M1\_13TeV\_pythia8        & 25.1\\
                             & \small QCD\_Pt-800to1000\_MuEnrichedPt5\_TuneCUETP8M1\_13TeV\_pythia8       & 4.71\\
                             & \small QCD\_Pt-1000toInf\_MuEnrichedPt5\_TuneCUETP8M1\_13TeV\_pythia8       & 1.62\\\hline
\multirow{6}{=}{QCD $e$ enriched}
                             & \small QCD\_Pt-30to50\_EMEnriched\_TuneCUETP8M1\_13TeV\_pythia8             & 6493800.0\\
                             & \small QCD\_Pt-50to80\_EMEnriched\_TuneCUETP8M1\_13TeV\_pythia8             & 2025400.0\\
                             & \small QCD\_Pt-80to120\_EMEnriched\_TuneCUETP8M1\_13TeV\_pythia8            & 478520.0\\
                             & \small QCD\_Pt-120to170\_EMEnriched\_TuneCUETP8M1\_13TeV\_pythia8           & 68592.0\\
                             & \small QCD\_Pt-170to300\_EMEnriched\_TuneCUETP8M1\_13TeV\_pythia8           & 18810.0\\
                             & \small QCD\_Pt-300toInf\_EMEnriched\_TuneCUETP8M1\_13TeV\_pythia8           & 1350.0\\

\hline
\end{longtable}

The background samples contain events of processes that are different from the \ttbar signal event but whose reconstructed final state passes the same selection criteria as applied to the signal. For example, consider the Drell-Yan (DY) process shown in Fig.~\ref{fig:Drell_Yan}. The DY process occurs in $pp$ collisions when a pair of oppositely charged leptons ($e$ or $\mu$) is created from the decay of an uncharged boson. The uncharged boson in turn is created from quark fusion. The cross section for the DY process is much larger than the cross section of the \ttbar process. The DY would form a a significant background if we select only one lepton as the other lepton could be misreconstructed as a jet. However, the importance of the DY background drops significantly when we impose the additional requirement of having at least 4 jets. A comprehensive account of the background processes is given in~\cite{Eichten:1984eu}.

\begin{figure}[htp]
\centering
\includegraphics[width=0.5\textwidth]{fig/Drell_Yan.pdf}
\caption{The Drell Yan process.}
\label{fig:Drell_Yan}
\end{figure}

Single $t$ and single $\overline{t}$ backgrounds have a negligible effect in the final selection stage and these samples are ignored at this stage of the analysis.

For creating the colour octet samples hard-scatter signal events were generated using \POWHEG-Box v2~\cite{Alioli:2010xd}. The colour strings in the LHE files are swithced in such a way that one quark from the decay of the \PW boson is colour connected to the \cPqt quark while the other one to the \cPqb quark. The \PW bosons and \cPqt quarks had to be removed from the LHE files lest that \PYTHIA complain of unphysical colour flow.

Initially the generator level selection of the fiducial phase space used in this analysis was implemented in a \RIVET~\cite{Buckley:2010ar} routine to ease future comparison with new generators and tunes. Afterwards the colour flipped dataset with 12 million events was produced. A \PYTHIA 8.2 tune adopted by the TOP group to control the number of jets in 13~\TeV simulations~\cite{Seidel:hdamp} was used. This tune uses a $h_{\text{damp}}$ factor equal to 1.5 times the top mass. The $h_{\text{damp}}$ factor suppresses \POWHEG real emissions by a factor $\frac{h^{2}}{\pt^{2}+h^{2}}$. The colour octet sample is listed in Table~\ref{tab:mcdatasets_flip}. We will occasionally refer to the colour octet \PW sample as the $\ttbar\ cflip$ sample.

\begin{table}[htb]
\begin{center}
\caption{Simulation samples for the colour octet \PW boson. We quote the cross section used to normalise the sample in the analysis.}
\label{tab:mcdatasets_flip}
\hspace*{-0.5cm}
\begin{tabular}{ llc }
\hline
Process & Dataset & $\sigma[pb]$\\
\multicolumn{3}{l}{\bf Background} \\
\hline
Colour octet \PW boson &  {\small TT\_TuneCUETP8M2T4\_13TeV-powheg-colourFlip-pythia8} & 832 \\
\hline
\end{tabular}
\end{center}
\end{table}

\section{Corrections applied to the simulation}
\label{sec:mccorrections}

Based on differences between data and simulated events different sets of corrections are applied to the latter.

\begin{description}

\item[Pileup re-weighting]

During each bunch crossing there are multiple \Pp\Pp collisions. The reconstructed tracks are combined into vertices, each vertex marking the spot of a \Pp\Pp collision. Pile-up refers to the number of \Pp\Pp colisions in each bunch crossing. A pile-up recorded in a real event is shown in Fig.~\ref{fig:pu}.

\begin{figure}[htp]
\centering
\includegraphics[width=0.5\textwidth]{fig/pu.png}
\caption{The $\rho$-$z$ view of an event in a high pile-up run 198609 showing 78 reconstructed vertices~\cite{Holzner:pu}.}
\label{fig:pu}
\end{figure}

However, the example in Fig.~\ref{fig:pu} is extreme. Pile-up depends on the number of protons in the bunch and the beam emittance and has been varying at different times of the operation of the LHC - see Fig.~\ref{fig:pileup_allYears}. The CMS detector has been designed with an average pile-up of 25 collisions in mind but the HL-CMS will have to be prepared for a pile-up of 140-200 collisions~\cite{Apollinari:2015bam}.

\begin{figure}[htp]
\centering
\includegraphics[width=0.5\textwidth]{fig/pileup_allYears.png}
\caption{Pile-up during different periods of the operation of the LHC~\cite{twiki:pu_public}.}
\label{fig:pileup_allYears}
\end{figure}

When preparing the MC samples also the pile-up value is determined. Additional minimum bias interactions are superimposed in order to include the effect of in-time (originating from the same bunch crossing) and out-of-time (originating from the previous bunch crossing) pileup in the events. Minimum bias refers to events that are selected with a “loose” trigger that accepts a large fraction of the overall inelastic cross section~\cite{Field:2011iq}. The generated pileup distribution is based on the configuration

SimGeneral.MixingModule.mix\_2016\_25ns\_Moriond17MC\_PoissonOOTPU\_cfi.

A minimum bias cross section of 69~mb is used to estimate the pileup distribution following the recommendations from~\cite{twiki:pileup}. A 5~\% uncertainty assigned to the minimum bias cross section assumed.

Fig.~\ref{fig:L4_1l4j2b2w_nvtx} shows the distribution of data compared to expectation in the number of primary vertices reconstructed. The agreement between data and Monte Carlo is not perfect, and is poorer in runs BCDEF than in GH. In order to equalise the pile-up distributions between data and MC each MC event is assigned a pile-up weight:

\begin{equation}
w_{\text{pu}}=\frac{N^{\text{data}}_{\text{pu}}}{N^{\text{MC}}_{\text{pu}}}
\end{equation}

\begin{figure}[htp]
\centering
  \def\twidth{0.45}
  \centering
  \subfloat[Pile-up distribution for runs BCDEF.]{%
    \includegraphics[width=\twidth\textwidth]{fig/L4_1l4j2b2w_nvtx_BCDEF}%
    \label{fig:L4_1l4j2b2w_nvtx_BCDEF}
  }\hfil
  \subfloat[Pile-up distribution for runs GH.]{%
    \includegraphics[width=\twidth\textwidth]{fig/L4_1l4j2b2w_nvtx_GH}%
    \label{fig:L4_1l4j2b2w_nvtx_GH}
  }
\caption{Pile-up distributions in Monte Carlo and data after the last step of event selection. }
\label{fig:L4_1l4j2b2w_nvtx}
\end{figure}

%% \begin{figure}[htp]
%%   \centering
%% \TODO{create plot}
%% \caption{Median energy density computed from FastJet in the ee (a) $\mu\mu$ (b) and e$\mu$ (c) channels.
%% }
%% \label{fig:purwgt_rho}
%% \end{figure}

\item[Lepton identification and isolation efficiency]

An efficiency of an algorithm to select a physics object according to a criterion is defined as 

\begin{equation}
\epsilon\equiv\frac{\text{N of objects that pass the criterion actually passed by the algorithm}}{\text{N of objects that pass the criterion}}.
\end{equation}

The efficiency is a measure of the ability of our real-world selection algorithm to select a physics object compared to an idealised selection algorithm that will select interesting physics objects flawlessly.

The lepton identification and isolation efficiency is measured using the tag-and-probe method~\cite{CMS-AN-2009-111}. This method uses known mass di-object resonances like $Z$, $J\Psi$ and $\Upsilon$. The ``tag'' is an object that passes a very tight set of criteria. The fake rate of a tag should be very small - $\ll 1\%$. The probe is the other object in the resonance selected according the particular selection criteria that are much looser than the selection criteria used for the tag. The efficiency is measured as:

\begin{equation}
\epsilon=\frac{N_{\text{pass}}}{N_{\text{all}}},
\end{equation}

where $N_{\text{pass}}$ is the number of probes passing the selection criteria, while $N_{\text{pass}}$ is the total number of probes counted.

The identification efficiency refers to the ability to identify a physics object X when it actually is a physics object X. For example, a jet with large electromagnetic content could be identified as an electron. Or hadron shower remnants could penetrate the muon system (punch-through) and could be identified as a muon. The identification efficiency depends on the \pt and $\eta$ of the physics object. Particularly it degrades for low \pt. Fig.~\ref{fig:CMS-EGM-13-001_Figure_024} shows the identification efficieny of electron as a function of \pt for different ranges of $\eta$.

\begin{figure}[htp]
\centering
  \def\twidth{0.45}
  \centering
  \subfloat[$\eta<0.8$.]{%
    \includegraphics[width=\twidth\textwidth]{fig/CMS-MUO-16-001_Figure_008-a.pdf}%
    \label{fig:CMS-EGM-13-001_Figure_024-a.pdf}
  }\hfil
  \subfloat[$<1.57\eta2$.]{%
    \includegraphics[width=\twidth\textwidth]{fig/CMS-MUO-16-001_Figure_008-b.pdf}%
    \label{fig:CMS-EGM-13-001_Figure_024-d.pdf}
  }
\caption{Efficiency as a function of electron \pt for dielectron events in data (dots) and DY simulation (triangles), for the medium working point of the sequential selection~\cite{Khachatryan:2015hwa}.}
\label{fig:CMS-EGM-13-001_Figure_024}
\end{figure}

Muon isolation is used to distinguish prompt muons from weakly decaying jets. It is used for muons that have already passed the identification criterion. Muon isolation is evaluated relative to the muon \pt by summing up energy in geometrical cone $R=\sqrt{(\Delta\eta)^{2}+(\Delta\phi)^{2}}$ surrounding the muon. The muon isolation efficiency degrades with lower \pt. Fig.~\ref{fig:CMS-MUO-16-001_Figure_008} shows the muon isolation efficiency as a function of the muon \pt and $\eta$. 

\begin{figure}[htp]
\centering
  \def\twidth{0.45}
  \centering
  \subfloat[Tag-and-probe efficiency for the tight PF isolation working point on top of the tight ID versus \pt for muons in the acceptance of the muon spectrometer.]{%
    \includegraphics[width=\twidth\textwidth]{fig/CMS-MUO-16-001_Figure_008-a.pdf}%
    \label{fig:CMS-MUO-16-001_Figure_008-a}
  }\hfil
  \subfloat[Tag-and-probe efficiency for the tight PF isolation working point on top of the tight ID versus $\eta$ for muons with $\pt> 20$ GeV.]{%
    \includegraphics[width=\twidth\textwidth]{fig/CMS-MUO-16-001_Figure_008-b.pdf}%
    \label{fig:CMS-MUO-16-001_Figure_008-b}
  }
\caption{Tag-and-probe efficiency for the tight PF isolation working point on top of the tight ID versus \pt for muons in the acceptance of the muon spectrometer, and versus $\eta$ for muons with $\pt> 20$ GeV, for 2015 data (circles), simulation (squares), and the ratio (bottom inset). The statistical uncertainties are smaller than the symbols used to display the measurements \cite{Sirunyan:2018fpa}.}
\label{fig:CMS-MUO-16-001_Figure_008}
\end{figure}

We correct for the difference in performance for the lepton identification in electrons and lepton identification and isolation in muons between data and simulation, by applying a \pt, $\eta$-dependent scale factor. As it will be detailed later (Chap.~\ref{chap:event_selection}) we make use of tight muons~\cite{twiki:MUO} and electrons~\cite{twiki:EGM}. As data-to-MC scale factors we use of the official values recommended by the POGs~\cite{twiki:MuonSF,twiki:EGMSF}.


\item[Trigger efficiency]

Trigger efficiency is measured on leptons that have already passed the ID (electrons) or ID+isolation selection (muons). We correct for the difference in performance of the High Level Trigger (HLT)~(\cite{Adam:2005zf}, \cite{Sphicas:2002gg}) used in data and simulation. The HLT trigger receives events from the L1 trigger at a maximum design rate 100~kHz, in practice less than a third of this value. It then further selects interesting events according to various physics programmes. It is completely implemented in software and is continuously updated. The HLT is run on a farm of about 1000 commodity PCs. For different physics programmes separate trigger paths are used. The HLT further reduces the event rate by a factor of about 1000. Its output rate is $\mathcal{O}(1)-\mathcal{O}(100)$ Hz - a rate that is acceptable by recording devices.

The HLT selection is a multistage process\footnote{It corresponds to a combination of Level 2 and Level 3 triggers used in other detector systems.}. The first step uses the calorimeter information. In the second step energy deposits in the calorimeter are combined with hits in the pixel detector. In the third step full track reconstruction is used. Each step of the trigger contributes to a loss of trigger efficiency.

Trigger efficiency is a function of the \pt and $\eta$ of the physics object. Particularly the efficiency drops at low \pt. Let us consider the isolated single-muon trigger as an example. Fig.~\ref{fig:CMS-MUO-16-001_Figure_008} shows the dependence of the efficiency of this trigger as a function of \pt and $\eta$.

\begin{figure}[htp]
\centering
  \def\twidth{0.45}
  \centering
  \subfloat[Isolated single-muon trigger efficiency as a function of \pt.]{%
    \includegraphics[width=\twidth\textwidth]{fig/CMS-MUO-16-001_Figure_008-a.pdf}%
    \label{fig:CMS-MUO-16-001_Figure_008-a}
  }\hfil
  \subfloat[Isolated single-muon trigger efficiency as a function of $\eta$.]{%
    \includegraphics[width=\twidth\textwidth]{fig/CMS-MUO-16-001_Figure_008-b.pdf}%
    \label{fig:CMS-MUO-16-001_Figure_008-b}
  }
\caption{Isolated single-muon trigger efficiencies measured with 2015 data (squares), simulation (circles), and the ratio (bottom inset). Results are plotted as a function of offline reconstructed muon \pt and $\eta$~\cite{Sirunyan:2018fpa}.}
\label{fig:CMS-MUO-16-001_Figure_008}
\end{figure}

Based on these differences \pt and $\eta$ scale factors are used. They are different for data taking perios BCDEF and GH as each used different thresholds for tracking. The scale factors are shown in Fig.~\ref{fig:muontriggerssf}.

\begin{figure}[htp]
\centering
  \def\twidth{0.45}
  \centering
  \subfloat[Isolated single-muon trigger efficiency scale factors for data taking periods BCDEF.]{%
    \includegraphics[width=\twidth\textwidth]{fig/muontriggersBCDEF.pdf}%
    \label{fig:muontriggersBCDEF}
  }\hfil
  \subfloat[Isolated single-muon trigger efficiency scale factors for data taking periods GH.]{%
    \includegraphics[width=\twidth\textwidth]{fig/muontriggersGH.pdf}%
    \label{fig:muontriggersGH}
  }
\caption{Isolated single-muon trigger efficiency scale factors for data taking periods BCDEFGH of 2016.}
\label{fig:muontriggerssf}
\end{figure}

The values used for the correction of trigger efficiencies are the ones proposed by the Top Trigger group~\cite{twiki:toptrig}.

\item[Generator level weights]

The generator level weights $w_{\text{gen}}$ are assigned by the generator. They are equal to 1 for \POWHEG but can be different from unity for other generators and systematic variations.

The simulated processes are scaled according to their effective integrated luminosity which can be computed from the sum of the per-event weights. The general formula applied to determine the number of events expected for a given process ($\hat{N}$), is:

\begin{equation}
\hat{N}=\mathcal{L}\cdot\sigma\cdot\frac{\sum_{i=1}^{\rm N_{sel}} w_i}{\sum_{i=1}^{\rm N_{gen}} w_i},
\label{eq:genwgts}
\end{equation}

where $\mathcal{L}$ is the integrated luminosity, $\sigma$ is a reference theory prediction for the inclusive cross section and $w_i$ are the per-event generator level weights.

The weight assigned to an event $w$ is a multiplicative combination of the pile-up weight $w_{\text{pu}}$, trigger efficiency scale factor $\text{sf}_{\text{trigger}}$, $\text{sf}_{\text{lepton\ ID+isolation}}$, generator level weight $w_{\text{gen}}$ and the inverse of total events generated $N_{\text{gen}}$ - Eq.~\ref{eq:ev_w}. 

\begin{equation}
w=w_{\text{pu}}\cdot\text{sf}_{\text{trigger}}\cdot\text{sf}_{\text{lepton\ ID+isolation}}\cdot w_{\text{gen}}\frac{1}{N_{\text{gen}}}
\label{eq:ev_w}
\end{equation}

In addition to assigning event weights each distribution of an observable of sample is scaled to integrated luminosity $\mathcal{L}$ and the theoretically predicted cross section $\sigma$ of the process associated with the sample. 

\item[Jet energy scale and resolution]
  The jet energy scale correction (JEC) is applied to bring jet response to unity. Jet response \JetResponse is defined as the ratio of the arithmetic mean of reconstructed jets \pt and the \pt calculated from the generated constituens of jets (particle level): 
  
\begin{equation}
\JetResponse\equiv\frac{<\pt>_{\text{reco}}}{<\pt>_{\text{ptcl}}}.    
\end{equation}

A reconstructed jet is matched to the generated (particle level) jet if the jet separation is within half of the jet distance parameter $R$, where $R\equiv\sqrt{\left(\eta_{\text{jet\ 1}} - \eta_{\text{jet\ 2}} \right)^{2}+\left(\phi_{\text{jet\ 1}} - \phi_{\text{jet\ 2}}\right)^{2}}$. If $R=0.5$ is used jet distance should be no more than 0.25.

The jet response is dependent on \pt, $\eta$ and jet size. Particularly it degrades for jet $\pt<30$~\GeV and is lower in the endcaps - see Fig.~\ref{fig:CMS-JME-13-004_Figure_010-a}. Jet energy scale corrections are applied using the so called \textsc{Summer16\_23Sep2016V4\_{Data,MC}} corrections~\cite{twiki:JES}. The JEC are effective to bring jet energy response to unity particularly for jets with $\pt>30$~\GeV - see Fig.~\ref{fig:CMS-JME-13-004_Figure_010-b}. 

\begin{figure}[htp]
\centering
  \def\twidth{0.45}
  \centering
  \subfloat[Simulated jet response $R$ versus $\left|\eta\right|$ for the jet distance parameter $R=0.5$.]{%
    \includegraphics[width=\twidth\textwidth]{fig/CMS-JME-13-004_Figure_010-a.pdf}%
    \label{fig:CMS-JME-13-004_Figure_010-a}
  }\hfil
  \subfloat[Simulated jet response $R$, after JEC have been applied, versus $p_{T\text{,ptcl}}$ for jet distance parameter $R=0.5$ in various $\left|\eta\right|$ regions.]{%
    \includegraphics[width=\twidth\textwidth]{fig/CMS-JME-13-004_Figure_010-b.pdf}%
    \label{fig:CMS-JME-13-004_Figure_010-b}
  }
\caption{Jet energy response before (a) and after (b) applying JEC. The illustration is from 2012~\TeV data with $\sqrt{s}=8$ due to unavailability of public results with Run II data~\cite{Khachatryan:2016kdb}. For a discussion of PF+CHS jets see text.}
\label{fig:CMS-JME-13-004_Figure_010}
\end{figure}

The PF+CHS jets referred to in Fig.~\ref{fig:CMS-JME-13-004_Figure_010} are particle flow jets to which charged hadron subtraction (CHS) has been applied. In this method tracks of charged hadrons unambiguously associated with pileup vertices are removed before clustering jets. It is a method to mitigate in-time pileup. CHS can remove approximately 50~\% of in-time pileup within tracker coverage.

The jet energy resolution (JER) is defined as the width of the distribution $\frac{p_{T\text{,reco}}}{p_{T,\text{ptcl}}}$ determined with a gaussian fit. JEC are applied before deriving JER. Jets have the worst energy resolutions among all physics objects. JER is dependent on pileup, \pt and $\eta$. Higher pile-up degrades JER due to contamination of tracks and energy deposits from other collisions. It degrades with low \pt and is worse in the endcaps than in the barrel. Fig.~\ref{fig:JER} shows JER versus \pt in the barrel for varying levels of pile-up.

\begin{figure}[htp]
\centering
  \def\twidth{0.45}
  \centering
    \includegraphics[width=\twidth\textwidth]{fig/CMS-JME-13-004_Figure_036-b}
\caption{JER versus \pt in the barrel for varying levels of pile-up $\mu$. The results are shown separately for PF+CHS jets with jet distance parameter $R=0.5$~\cite{Khachatryan:2016kdb}.}
\label{fig:JER}
\end{figure}

In simulation the nominal jet energy resolution is smeared using a \pt, $\eta$-dependent parameterization~\cite{twiki:JER}. The so called hybrid method is used. When a corresponding generated particle level jet is found the scaling method is used - Eq.~\ref{eq:scaling}.

\begin{equation}
c_{\text{JER}}=1 + (s_{\text{JER}}-1)\frac{\pt-p_{T\text{,ptcl}}}{\pt},
\label{eq:scaling}
\end{equation}

where $s$ is the scaling factor.

If the generated particle level jet is not found the stochastic scaling method is used - Eq.~\ref{eq:stochastic}.

\begin{equation}
c_{\text{JER}}=1+\mathcal{N}(0,\sigma_{JER})\sqrt{\max(s_{\text{JER}-1,0})}.
\label{eq:stochastic}
\end{equation}

Fig.~shows \ref{fig:CMS-JME-13-004_Figure_041} jet energy resolution data/MC scale factor versus $\left|\eta\right|$ for $\gamma$+jet data.

\begin{figure}[htp]
\centering
  \def\twidth{0.45}
  \centering
    \includegraphics[width=\twidth\textwidth]{fig/CMS-JME-13-004_Figure_043-b}
  \caption{Jet energy resolution data/MC scale factor versus $\left|\eta\right|$ for \cPgg+jet data collected at 8~\TeV (closed circles, solid area) compared to results at 7~\TeV (open circles, dashed area)~\cite{Khachatryan:2016kdb}. We illustrate Run I results due to unavailability of public results for Run II.}
  \label{fig:CMS-JME-13-004_Figure_041}
\end{figure}

In both cases alternative scenarios generated by shifting the corrections according to their uncertainties are considered and shall be discussed in detail in Chapter~\ref{chap:systematic_uncertainties}.

\item[\cPqb tagging efficiency]

The difference in performance of the \cPqb-tagging algorithm used in the analysis is accounted for by applying a \pt-dependent scale factor. As it will be detailed later (Chap.~\ref{chap:event_selection}), we make use of the medium working point of the Combined Secondary Vertex (v2) algorithm. The scale factors are used to correct a-posteriori the \cPqb-tagging decision in the simulation~\cite{twiki:BTV}. Fig.~\ref{fig:btag_sf} shows the data to simulation scale factors for \cPqb jets from the hadronic and lepton side of single-lepton \ttbar decay.

\begin{figure}[htp]
\centering
  \def\twidth{0.45}
  \centering
    \includegraphics[width=\twidth\textwidth]{fig/CMS-BTV-16-002_Figure_046-a.pdf}
\caption{Data-to-simulation scale factors for \cPqb jets from the hadronic or leptonic side of the single-lepton \ttbar decay as well as for their combination, as a function of the jet \pt for the medium working point of the CSVv2 tagger~\cite{Sirunyan:2017ezt}.}
\label{fig:btag_sf}
\end{figure}

\end{description}

